{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de951465",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "**⚠️ Important: DeepLabCut Environment Required**\n",
    "\n",
    "This notebook requires DeepLabCut to be installed and should be run in a DeepLabCut conda environment.\n",
    "\n",
    "DeepLabCut is a markerless pose estimation toolkit that uses deep learning to track user-defined body parts (Mathis et al., 2018).\n",
    "\n",
    "### Installation Instructions\n",
    "\n",
    "For detailed installation instructions, see the [DeepLabCut installation guide](https://deeplabcut.github.io/DeepLabCut/docs/installation.html).\n",
    "\n",
    "### Running This Notebook\n",
    "\n",
    "Before running this notebook:\n",
    "- Ensure you have activated the DeepLabCut environment: `conda activate DEEPLABCUT`\n",
    "- Select the correct kernel in Jupyter: Kernel → Change Kernel → DEEPLABCUT (Python 3.9.19)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Reference\n",
    "\n",
    "**Mathis, A., Mamidanna, P., Cury, K.M. et al.** (2018). DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. *Nature Neuroscience*, 21, 1281–1289. https://doi.org/10.1038/s41593-018-0209-y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08276da9",
   "metadata": {},
   "source": [
    "# Install Necessary Packages (Only need to do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6889eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b12f7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b75a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the toolbox (takes several seconds)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pylab import *\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import scipy.stats as sp\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# DeepLabCut Import\n",
    "import deeplabcut\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "os.environ['DLClight'] = 'True'\n",
    "print(tf.__version__)\n",
    "\n",
    "# Specify path to dlc_utils file\n",
    "custom_utils_path = Path(os.getcwd()).parent/'src'/'compass_labyrinth'/'behavior'/'pose_estimation'\n",
    "sys.path.append(str(custom_utils_path))\n",
    "\n",
    "import dlc_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869a510",
   "metadata": {},
   "source": [
    "### Specify Paths and Other Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19278de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONFIGURE PATHS FOR YOUR LOCAL SYSTEM #####\n",
    "\n",
    "# === VIDEO FILE LOCATIONS ===\n",
    "# NOTE: The following paths are specific to Palop Lab workflow for copying videos from multiple recording computers\n",
    "# For most users: skip video_path_1 and video_path_2, and only set videofile_path to your video directory\n",
    "\n",
    "# Original video locations from recording computers (Palop Lab specific - IGNORE FOR MOST CASES)\n",
    "video_path_1 = r'D:\\Gladstone Dropbox\\Palop Lab\\Patrick\\Machine Learning Behavioral Analysis\\Labyrinth\\Noldus\\20251019_AppSAA_DSI_Labyrinth\\Media Files'\n",
    "video_path_2 = ''  # Leave empty if not using multiple computers\n",
    "\n",
    "# Central video location where all videos are stored for processing\n",
    "source_data_path = r'D:\\Gladstone Dropbox\\Palop Lab\\Patrick\\Machine Learning Behavioral Analysis\\Labyrinth\\Noldus\\20251019_AppSAA_DSI_Labyrinth\\Media Files\\source_data_test'\n",
    "videofile_path = source_data_path\n",
    "\n",
    "# === DEEPLABCUT CONFIGURATION ===\n",
    "# Path to your trained DLC model config file\n",
    "dlc_config_path = Path(r'D:\\Gladstone Dropbox\\Palop Lab\\Patrick\\Machine Learning Behavioral Analysis\\Labyrinth\\DeepLabCut Projects\\Labyrinth-Nick-2023-03-13\\config.yaml')\n",
    "dlc_scorer = 'DLC_resnet50_LabyrinthMar13shuffle1_1000000'  # Scorer name from your DLC model\n",
    "\n",
    "# === OUTPUT PATHS ===\n",
    "# Grid-based files for HMM state heatmap visualizations\n",
    "grid_path = source_data_path\n",
    "\n",
    "# Output directory for figures\n",
    "figure_path = os.path.join(source_data_path, 'figures')\n",
    "\n",
    "# === METADATA ===\n",
    "# Excel file containing animal and session metadata\n",
    "user_metadata_file_path = r'D:\\Gladstone Dropbox\\Palop Lab\\Patrick\\Machine Learning Behavioral Analysis\\DLC Info Sheets\\20250725_LG124KI3_Cohort4_DLC_InfoSheet_v1.xlsx'\n",
    "trial_type = 'Labyrinth_DSI'  # Sheet/tab name in the metadata file\n",
    "\n",
    "# === SUMMARY ===\n",
    "print(\"=== Path Configuration ===\")\n",
    "print(f\"Video Source 1: {video_path_1}\")\n",
    "print(f\"Video Source 2: {video_path_2}\")\n",
    "print(f\"Central Video Location: {videofile_path}\")\n",
    "print(f\"Metadata: {user_metadata_file_path}\")\n",
    "print(f\"Figures Output: {figure_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a4cff",
   "metadata": {},
   "source": [
    "# Import Mouse Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Metadata to metadata directory\n",
    "mouseinfo = dlc_utils.import_cohort_metadata(user_metadata_file_path, trial_type)\n",
    "\n",
    "# Validate the metadata\n",
    "dlc_utils.validate_metadata(mouseinfo)\n",
    "\n",
    "# Display summary of the metadata\n",
    "dlc_utils.display_metadata_summary(mouseinfo)\n",
    "\n",
    "mouseinfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13955e98",
   "metadata": {},
   "source": [
    "# OPTIONAL: Copy and rename videos from original location to VIDEOFILE_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10795135",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now(); print(now)\n",
    "\n",
    "# 1. Save first frames\n",
    "copy_results = dlc_utils.copy_and_rename_videos(\n",
    "            mouseinfo_df=mouseinfo,\n",
    "            video_paths=[video_path_1], \n",
    "            destination_path=videofile_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713505f8",
   "metadata": {},
   "source": [
    "# Get DeepLabCut Cropping Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save first frames for all videos\n",
    "now = datetime.datetime.now(); print(datetime.datetime.now())\n",
    "\n",
    "print(\"\\nSaving first frames for all videos...\")\n",
    "frame_results = dlc_utils.batch_save_first_frames(\n",
    "    mouseinfo_df=mouseinfo,\n",
    "    video_directory=videofile_path,\n",
    "    frames_directory=source_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef950284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DLC cropping bounds for a all videos\n",
    "now = datetime.datetime.now(); print(datetime.datetime.now())\n",
    "\n",
    "coordinates_dict = dlc_utils.batch_get_boundary_and_cropping(\n",
    "    mouseinfo_df=mouseinfo, \n",
    "    frames_directory=source_data_path,\n",
    "    cropping_directory=source_data_path,\n",
    "    boundaries_directory=source_data_path,\n",
    "    reprocess_existing=False # set to True if you'd like to redo boundaries\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DLC cropping bounds for a individual video\n",
    "coordinates_dict = dlc_utils.get_labyrinth_boundary_and_cropping(\n",
    "    frames_directory=source_data_path,\n",
    "    cropping_directory=source_data_path,\n",
    "    boundaries_directory=source_data_path,\n",
    "    session='Session0007',\n",
    "    chamber_info=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83796c2f",
   "metadata": {},
   "source": [
    "# Analyze the Videos with DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare sessions\n",
    "sessions_to_analyze, prep_summary = dlc_utils.prepare_dlc_analysis(\n",
    "    mouseinfo, \n",
    "    videofile_path, \n",
    "    source_data_path, \n",
    "    source_data_path\n",
    ")\n",
    "\n",
    "# Print preparation summary\n",
    "print(f\"\\nPreparation Summary:\")\n",
    "print(f\"Ready for analysis: {prep_summary['ready_for_analysis']}\")\n",
    "print(f\"Already analyzed: {prep_summary['skipped_existing']}\")\n",
    "print(f\"Missing videos: {prep_summary['missing_video']}\")\n",
    "print(f\"Missing coordinates: {prep_summary['missing_coordinates']}\")\n",
    "\n",
    "# Now run DLC analysis in the correct environment\n",
    "analysis_results = []\n",
    "for session in sessions_to_analyze:\n",
    "    session_start = datetime.datetime.now()\n",
    "    print(f\"\\nAnalyzing {session['session_name']}...\")\n",
    "    \n",
    "    deeplabcut.analyze_videos(\n",
    "        dlc_config_path,\n",
    "        [session['video_path']],\n",
    "        shuffle=1,\n",
    "        videotype=\".mp4\",\n",
    "        save_as_csv=True,\n",
    "        cropping=session['cropping_coords'],\n",
    "        destfolder=session['results_path'],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30915fd8",
   "metadata": {},
   "source": [
    "# Create Grids and save as Grid Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e75a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "print(f\"\\nCreating grids for {len(mouseinfo)} sessions...\")\n",
    "\n",
    "# Run batch grid creation\n",
    "grid_results = dlc_utils.batch_create_grids(\n",
    "    mouseinfo_df=mouseinfo,\n",
    "    boundaries_directory=source_data_path,\n",
    "    grid_files_directory=source_data_path,\n",
    "    cropping_directory=source_data_path,\n",
    "    num_squares=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2fdf5",
   "metadata": {},
   "source": [
    "# Initial Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1c016",
   "metadata": {},
   "source": [
    "### Plot the Scatterplot with Grid overlayed for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "print(\"\\n--- Batch Processing Example ---\")\n",
    "batch_results = dlc_utils.batch_create_grid_scatter_plots(\n",
    "    mouseinfo_df=mouseinfo,\n",
    "    dlc_results_directory=source_data_path,\n",
    "    grid_files_directory=source_data_path,\n",
    "    figures_directory=figure_path,\n",
    "    dlc_scorer=dlc_scorer,\n",
    "    bodypart='sternum',\n",
    "    likelihood_threshold=0.6, # rough threshold to visualize when mice are in maze\n",
    "    figure_size=(3, 3),\n",
    "    show_plots=False  # Don't display plots during batch processing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027762b3",
   "metadata": {},
   "source": [
    "### Create Trajectory Plots with Grid Overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4694b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "print(\"\\n--- Different Colormaps Example ---\")\n",
    "colormaps = ['viridis']\n",
    "\n",
    "for colormap in colormaps:\n",
    "    print(f\"\\nCreating trajectory plots with {colormap} colormap...\")\n",
    "    batch_results = dlc_utils.batch_create_trajectory_plots(\n",
    "        mouseinfo_df=mouseinfo,  # Just first 2 sessions\n",
    "        dlc_results_directory=source_data_path,\n",
    "        grid_files_directory=source_data_path,\n",
    "        figures_directory=os.path.join(figure_path, \"trajectory_plots\"),\n",
    "        dlc_scorer=dlc_scorer,\n",
    "        bodypart='sternum',\n",
    "        likelihood_threshold=0.6,\n",
    "        colormap=colormap,\n",
    "        show_plots=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bdef0",
   "metadata": {},
   "source": [
    "# Create CSVs with Grid Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "results = dlc_utils.batch_append_grid_numbers(\n",
    "    mouseinfo_df=mouseinfo,\n",
    "    grid_files_directory=source_data_path,\n",
    "    dlc_results_directory=source_data_path,\n",
    "    dlc_scorer=dlc_scorer,\n",
    "    save_directory=source_data_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
