#!/usr/bin/env Rscript

###########################################################################
## Project: Survival and hazard rate estimation of the labyrinth data
## Author: Reuben Thomas
##
## Script Goal: Performs survival analyses to compare distributions of total frame nos and number of grid positions between the WT and AppSAA mice
## to reach chosen nodes (reward or neutral) in the labyrinth for the first time as each mouse enters the labyrinth for a bout
##
## Usage : Takes as input the two R objects generated by the 1.generate_grid_trajectories.R script
##
###########################################################################

rm(list = ls())

require(dplyr)
require(magrittr)
require(zoo)
require(ggplot2)
require(lmerTest)
require(DHARMa)
require(nhm)
require(msm)
require(survival)
require(coxme)
require(readxl)


pheno_data <- read.csv("~/Dropbox (Gladstone)/scripts/JP_PH01/230504 Denali cohort3 MICEv2.csv", header = TRUE)
pheno_data %<>% mutate(Genotype = Genotype.1) %>% select(-Genotype.1)

pheno_data_learning <- read_xlsx("~/Dropbox (Gladstone)/scripts/JP_PH01/20230302_AppSAA_Cohort3_Labyrinth_DLC_Info_Sheet_v3.xlsx", sheet = "Learning Trial")
pheno_data_learning %<>% mutate(Session.1 = Session) %>% select(Session.1, `New Mouse ID`)
pheno_data %<>% merge(., pheno_data_learning, all.x = TRUE)
colnames(pheno_data)[1] <- "Session.learning"

pheno_data %<>% select(-Session, -order)




all_mice_entry_exit_times_learning <- readRDS(paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/all_mice_entry_exit_times_learning_update_bout_defs_include_mouseID_1842.rds"))
grid_trajectories_learning <- readRDS(paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/grid_trajectories_learning_update_bout_defs_include_mouseID_1842.rds"))

##count number of visits to reward node
get_reward_node_times <- function(session_index, trial, pheno_data, reward_nodes) {
  #print(session_index)
  session_number <- NA
  if(trial == "learning") {
    session_number <- pheno_data$Session.learning[session_index]
    grid_trajectories <- grid_trajectories_learning[[session_index]]
  }
  else{
    session_number <- pheno_data$Session.probe[session_index]
    grid_trajectories <- grid_trajectories_probe[[session_index]]
  }
  
  temp_reward_node_times <- data.frame(duration = NA,
                                       censor = NA,
                                       no_rewards = NA,
                                       entry_time = NA,
                                       ngrids = NA,
                                       path_length = NA,
                                       Session = rep(session_number, 1))
  
  if(length(grid_trajectories) > 0) {
    temp_data <- grid_trajectories[[1]]
    temp_reward_node_times <- data.frame(duration = rep(NA, length(grid_trajectories)),
                                         censor = rep(1, length(grid_trajectories)),
                                         no_rewards = rep(0, length(grid_trajectories)),
                                         entry_time = rep(temp_data$entry_time[1], length(grid_trajectories)),
                                         ngrids = rep(length(unique(temp_data$node)), length(grid_trajectories)),
                                         path_length = rep(nrow(temp_data), length(grid_trajectories)),
                                         Session = rep(session_number,length(grid_trajectories)))
    count_reach_rewards <- 0
    for(e in 1:length(grid_trajectories)) {
      temp_data <- grid_trajectories[[e]]
      reward_indices <- which(temp_data$node == reward_nodes[1])
      for(r in 2:length(reward_nodes)) {
        reward_indices %<>% union(., which(temp_data$node == reward_nodes[r]))
      }
      reward_indices %<>% sort(.)
      #print(c(e, reward_indices))
      #print(reward_indices)
      if(length(reward_indices) == 0) {
        #duration
        temp_reward_node_times[e,1] <- sum(temp_data$duration)
        #censoring
        temp_reward_node_times[e,2] <- 1
        #previous rewards
        temp_reward_node_times[e,3] <- count_reach_rewards
        #entry time
        temp_reward_node_times[e,4] <- temp_data$entry_time[1]
        #unique nodes
        temp_reward_node_times[e,5] <- length(unique(temp_data$node))
        #path length
        temp_reward_node_times[e,6] <- nrow(temp_data)
      }else{
        #duration for first reaching the reward node on entry
        temp_reward_node_times[e,1] <- sum(temp_data$duration[1:reward_indices[1]])
        #censoring
        temp_reward_node_times[e,2] <- 0
        #previous rewards
        temp_reward_node_times[e,3] <- count_reach_rewards
        count_reach_rewards %<>% add(., length(reward_indices))
        #entry time
        temp_reward_node_times[e,4] <- temp_data$entry_time[1]
        #unique nodes
        temp_reward_node_times[e,5] <- length(unique(temp_data$node))
        #path-length
        temp_reward_node_times[e,6] <- reward_indices[1]
      }
    }
  }
  return(temp_reward_node_times)
}







##filter out animals
WT_sessions_to_use = c(7,8,11,12,15,16,19,23,24,28,31,39,44)
AppSAA_sessions_to_use = c(5,9,10,14,17,18,20,21,22,25,26,29,30,33,34,37,38,41,43)
sessions_to_use = append(WT_sessions_to_use, AppSAA_sessions_to_use) 

step_length = 20
max_bin = 100
#metric <- "duration"
metric <- "path_length"
zone <- "reward"
#zone <- "neutral"
metric_data <- NULL
hazard_ratios <- NULL
##test binning every 5 extra rewards
for(binned_no_rewards in seq(step_length,round(max_bin/step_length)*step_length, by=step_length)) {
  print(binned_no_rewards)
  all_mice_entry_exit_times_learning <- readRDS(paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/all_mice_entry_exit_times_learning_update_bout_defs_include_mouseID_1842.rds"))
  grid_trajectories_learning <- readRDS(paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/grid_trajectories_learning_update_bout_defs_include_mouseID_1842.rds"))

  if(zone == "reward")
    reward_nodes <- c(84, 85)
  else
    reward_nodes <- c(107, 119, 131, 143)
  
  temp_learning <- lapply(1:nrow(pheno_data), get_reward_node_times, "learning", pheno_data, reward_nodes)
  temp_learning %<>% do.call("rbind", .)
  
  reward_node_times_learning <- lapply(1:nrow(pheno_data), get_reward_node_times, "learning", pheno_data, reward_nodes)
  reward_node_times_learning %<>% do.call("rbind", .)
  reward_node_times_learning %<>% mutate(Session.learning = Session)
  reward_node_times_learning %<>% select(-Session)
  reward_node_times_learning %<>% merge(., pheno_data, all.x = TRUE)
  reward_node_times_learning %<>% mutate(status = (1-censor))
  reward_node_times_learning %<>% mutate(trial = rep("learning", nrow(.)))
  
  ###ALTERNATE BINNED ANALYSES
  reward_node_times_learning %<>% mutate(reward01 = rep(NA, nrow(.)))
  

  reward_node_times_learning$reward01[reward_node_times_learning$no_rewards <= (step_length) ] <- paste0("previous_",step_length,"_visits")
  reward_node_times_learning$reward01[reward_node_times_learning$no_rewards > binned_no_rewards &
                                        reward_node_times_learning$no_rewards <= (binned_no_rewards+step_length)] <- paste0("next_",step_length,"_visits")
  
  reward_node_times_learning %<>% dplyr::filter(!is.na(reward01))
  reward_node_times_learning %<>% mutate(reward01 = as.factor(reward01))
  
  
  ###ALTERNATE BINNED ANALYSES
  
  reward_node_times_learning %<>% mutate(genotype_reward = paste(Genotype, reward01, sep = "_"))
  reward_node_times_learning %<>% filter(Session.learning %in% sessions_to_use)
  
  fit_data <- reward_node_times_learning
  
  sformula <- as.formula(paste0("Surv(", metric,",status) ~ genotype_reward"))
  char_formula <- paste0("(Surv(", metric,", status) ~ genotype_reward)") 
  if(metric == "duration")
    km_fit_duration <- survfit(Surv(duration,status) ~ genotype_reward, data = fit_data)
  if(metric == "path_length")
    km_fit_duration <- survfit(Surv(path_length,status) ~ genotype_reward, data = fit_data)
  #km_fit_duration <- survfit(sformula, data = fit_data)
  #plot(km_fit_duration, col = c("red", "darkred", "blue", "darkblue"),  lty = c(1,2,1,2), main = binned_no_rewards)
  
  fit_data %<>% mutate(genotype_reward = as.factor(genotype_reward))
  me_formula <- as.formula(paste0("Surv(", metric,",status) ~ (1|Session.learning) + genotype_reward"))
  fit_data_wt <- fit_data %>% filter(Genotype == "WT") %>% mutate(genotype_reward = as.factor(genotype_reward), 
                                                                  genotype_reward = droplevels(genotype_reward),
                                                                  genotype_reward = relevel(genotype_reward, ref = paste0("WT_previous_",step_length,"_visits")))
  sfit_wt <- coxme(me_formula ,data = fit_data_wt)
  sumsfit_wt <- summary(sfit_wt)

  fit_data_ki <- fit_data %>% filter(Genotype == "KI") %>% mutate(genotype_reward = as.factor(genotype_reward), 
                                                                  genotype_reward = droplevels(genotype_reward),
                                                                  genotype_reward = relevel(genotype_reward, ref = paste0("KI_previous_",step_length,"_visits")))
  
  sfit_ki <- coxme(me_formula ,data = fit_data_ki)
  sumsfit_ki <- summary(sfit_ki)
  
  
  temp_res <- data.frame(Genotype = c("WT", "KI"),
                         HR = c(sumsfit_wt$coefficients[1,2], sumsfit_ki$coefficients[1,2]),
                         se_HR = c(sumsfit_wt$coefficients[1,3], sumsfit_ki$coefficients[1,3]),
                         bin = rep(binned_no_rewards, 2))
  
  hazard_ratios %<>% rbind(., temp_res)
   
  #print(binned_no_rewards)
 
  fit_data_next <- fit_data %>% filter(reward01 == paste0("next_", step_length, "_visits")) %>% mutate(Genotype = as.factor(Genotype), 
                                                                  Genotype = relevel(Genotype, ref = "WT"))
  meg_formula <- as.formula(paste0("Surv(", metric,",status) ~ (1|Session.learning) + Genotype"))
  sfit_next <- coxme(meg_formula ,data = fit_data_next)
  sumsfit_next <- summary(sfit_next)
  
  require(survminer)
  #pdf(paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/survial_curves_", metric, "_binned_interval_lower_", (binned_no_rewards-step_length), "_upper_",binned_no_rewards,"_target_", zone, "_zone.pdf"))
  p <- (ggsurvplot(km_fit_duration,
             data = fit_data,
             surv.median.line = "hv",
             palette = c(rep("darkred", 2), rep("darkblue", 2)),
             linetype = rep(c(1,3), 2),
             xlim = c(0,500),
             #break.x.by = 500,
             censor = FALSE,
             xlab = metric,
             ylab = "Fraction animals reaching target zone",
             # legend.labs = c(paste0("AppSAA ", (binned_no_rewards), "-", (binned_no_rewards+step_length), " prior visits"), 
             #                 paste0("AppSAA ", (binned_no_rewards-step_length), "-", (binned_no_rewards), " prior visits"), 
             #                 paste0("WT ", (binned_no_rewards), "-", (binned_no_rewards+step_length), " prior visits"), 
             #                 paste0("WT ", (binned_no_rewards-step_length), "-", (binned_no_rewards), " prior visits")),
             legend.labs = c(paste0("AppSAA ", (binned_no_rewards), "-", (binned_no_rewards+step_length), " prior visits"), 
                             paste0("AppSAA ", (0), "-", (step_length), " prior visits"), 
                             paste0("WT ", (binned_no_rewards), "-", (binned_no_rewards+step_length), " prior visits"), 
                             paste0("WT ", (0), "-", (step_length), " prior visits")),
             
             font.x = 20,
             font.y = 20,
             font.tickslab = 20) )
  plot <- p$plot + theme(legend.text = element_text(size = 20)) + theme(legend.position = "right", 
                         legend.direction = "vertical") 
    # geom_vline(xintercept = c(75, 100, 200), lty=2) +
    # geom_hline(yintercept = 0.5, lty=2)
  print(plot)
  # plot %>% ggsave(plot =.,
  #                 filename = paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/AppSAA_study_survival_curves_March_2025/survial_curves_", metric, "_reference_0_to_", (step_length), "_rewards_compared_to_",binned_no_rewards,"_to_", (binned_no_rewards+step_length),"_interval_target_", zone, "_zone.pdf"),
  #                 width = 15,
  #                 height = 10)
  #dev.off()

  temp_metric_data <- reward_node_times_learning %>%
    filter(censor == 0) %>%
    group_by(genotype_reward, Session.learning) %>%
    summarise(median_metric = median(.data[[metric]]),
              mean_metric = mean(.data[[metric]]))
  temp_metric_data %<>% group_by(genotype_reward) %>%
    summarise(median_median_metric = median(median_metric),
              mean_median_metric = mean(median_metric),
              se_median_metric = sd(median_metric)/sqrt(n()),
              median_mean_metric = median(mean_metric),
              mean_mean_metric = mean(mean_metric))
  temp_metric_data %<>% mutate(bin = rep(binned_no_rewards, nrow(.)))
  metric_data %<>% rbind(., temp_metric_data)
}


p <- ggplot(hazard_ratios, aes(x=bin, y=HR, color = Genotype)) +
  geom_point(position=position_dodge(width=5)) +
  geom_line(position=position_dodge(width=5)) + 
  #geom_smooth(span = 0.4, se = FALSE) +
  geom_hline(yintercept = 1, lty=2) +
  geom_errorbar(aes(ymin = HR - 1.96*se_HR, ymax = HR + 1.96*se_HR),
                position=position_dodge(width=5)) +
  ggtitle(paste0("Visits to ",zone," zones")) +
  xlab("No. of visits") +
  ylab(paste0("Hazard ratio (", metric ,": next ", step_length," vs. first. ",  step_length," visits)")) +
  theme_bw() +
  theme(text = element_text(size = 16))

p %>% ggsave(plot = .,
             filename = paste0("~/Dropbox (Gladstone)/scripts/JP_PH01/AppSAA_study_survival_curves_March_2025/Hazard_ratio_",  metric, "_reference_0_to_", (step_length), "_rewards_compared_to_",binned_no_rewards,"_to_", (binned_no_rewards+step_length),"_interval_target_", zone, "_zone_95_percent_confidence_intervals.pdf"),
             width = 10,
             height = 7) 
